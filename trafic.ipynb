{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pip install opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (4.5.5.64)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from opencv-python) (1.21.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Needed Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import cv\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
    "from numba import jit, cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First storing data for preprocesssing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "classes = 43\n",
    "cur_path = os.getcwd()\n",
    "\n",
    "#Retrieving the images and their labels \n",
    "for i in range(classes):\n",
    "    path = os.path.join(cur_path,'train',str(i))\n",
    "    images = os.listdir(path)\n",
    "    for a in images:\n",
    "        try:\n",
    "            image = Image.open(path + '\\\\'+ a)\n",
    "            image = image.resize((30,30))\n",
    "            image = np.array(image)\n",
    "            data.append(image)\n",
    "            labels.append(i)\n",
    "        except:\n",
    "            print(\"Error loading image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "for j in range(43,45):\n",
    "    path1 = os.path.join(cur_path,'train',str(j))\n",
    "    directory = os.listdir(path1)\n",
    "    for i in directory:\n",
    "        try:\n",
    "            test_image = image.load_img(f\"{path1}\\{i}\", target_size = (30, 30))\n",
    "            test_image = image.img_to_array(test_image)\n",
    "            data.append(list(test_image))\n",
    "            labels.append(j)\n",
    "        except:\n",
    "            print(\"error\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47209, 30, 30, 3) (47209,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Converting lists into numpy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# # print(data)\n",
    "print(data.shape, labels.shape)\n",
    "#Splitting training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=44)\n",
    "\n",
    "# print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "# #Converting the labels into one hot encoding\n",
    "y_train = to_categorical(y_train, 45)\n",
    "y_test = to_categorical(y_test, 45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_shape=X_train.shape[1:]))\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(45, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Compilation of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "591/591 [==============================] - 52s 88ms/step - loss: 0.2928 - accuracy: 0.8791 - val_loss: 0.1637 - val_accuracy: 0.9045\n",
      "Epoch 2/20\n",
      "591/591 [==============================] - 55s 94ms/step - loss: 0.2940 - accuracy: 0.8783 - val_loss: 0.1622 - val_accuracy: 0.9081\n",
      "Epoch 3/20\n",
      "591/591 [==============================] - 55s 94ms/step - loss: 0.2874 - accuracy: 0.8808 - val_loss: 0.1650 - val_accuracy: 0.9147\n",
      "Epoch 4/20\n",
      "591/591 [==============================] - 55s 93ms/step - loss: 0.2640 - accuracy: 0.8872 - val_loss: 0.1559 - val_accuracy: 0.9180\n",
      "Epoch 5/20\n",
      "591/591 [==============================] - 53s 90ms/step - loss: 0.2609 - accuracy: 0.8875 - val_loss: 0.1632 - val_accuracy: 0.9135\n",
      "Epoch 6/20\n",
      "591/591 [==============================] - 55s 94ms/step - loss: 0.2796 - accuracy: 0.8827 - val_loss: 0.1799 - val_accuracy: 0.9024\n",
      "Epoch 7/20\n",
      "591/591 [==============================] - 55s 94ms/step - loss: 0.2766 - accuracy: 0.8837 - val_loss: 0.1580 - val_accuracy: 0.9136\n",
      "Epoch 8/20\n",
      "591/591 [==============================] - 57s 97ms/step - loss: 0.2657 - accuracy: 0.8877 - val_loss: 0.1572 - val_accuracy: 0.9147\n",
      "Epoch 9/20\n",
      "591/591 [==============================] - 57s 97ms/step - loss: 0.2587 - accuracy: 0.8911 - val_loss: 0.1544 - val_accuracy: 0.9158\n",
      "Epoch 10/20\n",
      "591/591 [==============================] - 58s 98ms/step - loss: 0.2807 - accuracy: 0.8853 - val_loss: 0.1800 - val_accuracy: 0.9115\n",
      "Epoch 11/20\n",
      "591/591 [==============================] - 61s 103ms/step - loss: 0.2883 - accuracy: 0.8811 - val_loss: 0.1819 - val_accuracy: 0.9126\n",
      "Epoch 12/20\n",
      "591/591 [==============================] - 63s 107ms/step - loss: 0.2753 - accuracy: 0.8853 - val_loss: 0.1716 - val_accuracy: 0.9074\n",
      "Epoch 13/20\n",
      "591/591 [==============================] - 57s 96ms/step - loss: 0.2727 - accuracy: 0.8833 - val_loss: 0.1626 - val_accuracy: 0.9120\n",
      "Epoch 14/20\n",
      "591/591 [==============================] - 57s 97ms/step - loss: 0.2872 - accuracy: 0.8837 - val_loss: 0.1793 - val_accuracy: 0.9114\n",
      "Epoch 15/20\n",
      "591/591 [==============================] - 54s 92ms/step - loss: 0.2621 - accuracy: 0.8885 - val_loss: 0.1636 - val_accuracy: 0.9152\n",
      "Epoch 16/20\n",
      "591/591 [==============================] - 54s 91ms/step - loss: 0.2678 - accuracy: 0.8883 - val_loss: 0.1616 - val_accuracy: 0.9094\n",
      "Epoch 17/20\n",
      "591/591 [==============================] - 54s 91ms/step - loss: 0.2591 - accuracy: 0.8905 - val_loss: 0.1494 - val_accuracy: 0.9200\n",
      "Epoch 18/20\n",
      "591/591 [==============================] - 54s 91ms/step - loss: 0.2528 - accuracy: 0.8931 - val_loss: 0.1585 - val_accuracy: 0.9169\n",
      "Epoch 19/20\n",
      "591/591 [==============================] - 63s 107ms/step - loss: 0.2388 - accuracy: 0.8960 - val_loss: 0.1567 - val_accuracy: 0.9166\n",
      "Epoch 20/20\n",
      "591/591 [==============================] - 74s 125ms/step - loss: 0.2800 - accuracy: 0.8881 - val_loss: 0.3236 - val_accuracy: 0.8681\n"
     ]
    }
   ],
   "source": [
    "# #Compilation of the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# @jit(target =\"cuda\")\n",
    "# epoch = 50\n",
    "#more accuracy increase the epochs size\n",
    "history = model.fit(X_train, y_train, batch_size=64, epochs=20, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAving the Model for further Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Alert_classifier.h5\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "669c57335d814790a0a8ea20dc08c100929a5b6e7176d5937f3f567eb2cddf61"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
